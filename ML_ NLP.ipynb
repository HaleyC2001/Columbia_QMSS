{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7120a753-30da-46cf-8b05-46b08d0cf7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/haleychen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "def read_pickle(path_in, name_in):\n",
    "    return pickle.load(open(path_in + name_in + \".pk\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c45f728-cf05-4d21-8ef1-ba23515ab948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_pickle(\"/Users/haleychen/Downloads/\", \"hw4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a76921-591a-44ec-96e0-fad78d7981bc",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82257c88-c6a0-48c6-a5eb-ed4927a25780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     We use essential cookies to make Venngage wor...\n",
       "1    A legal contract is a written document that is...\n",
       "2     November 27 2023 14 min Author Olga Asheychik...\n",
       "3    Accelerate contracts with AI native workflows ...\n",
       "4    Create smarter agreements commit to them more ...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data['body']\n",
    "df_copy=df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808d7796-6092-44fe-920a-3e558c82de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Remove Stop Words\n",
    "def rem_sw(text):\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    sw = set(stopwords.words('english'))\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in sw])\n",
    "\n",
    "# 2. Stemming or Lemmatization\n",
    "def stem_fun(text, method='ps'):\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    words = text.split()\n",
    "    if method == 'ps':\n",
    "        return ' '.join([stemmer.stem(w) for w in words])\n",
    "    elif method == 'lemma':\n",
    "        return ' '.join([lemmatizer.lemmatize(w) for w in words])\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'ps' (PorterStemmer) or 'lemma'\")\n",
    "\n",
    "# 3. Vectorization (Count / TF-IDF)\n",
    "def vec_fun(text_series, m_in=1, n_in=1, vec_type='tf', o_path=None):\n",
    "    if vec_type == \"tf\":\n",
    "        vectorizer = CountVectorizer(ngram_range=(m_in, n_in))\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(m_in, n_in))\n",
    "    \n",
    "    vec_data = vectorizer.fit_transform(text_series)\n",
    "    df_out = pd.DataFrame(vec_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    if o_path:\n",
    "        os.makedirs(os.path.dirname(o_path), exist_ok=True)\n",
    "        with open(o_path, 'wb') as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59b3649-f2fc-42a3-950d-c651a6fcad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = data['body']  \n",
    "\n",
    "# Apply stopword removal, then stemming/lemmatization, then vectorization\n",
    "df = df.apply(rem_sw)  # Remove stopwords\n",
    "df = df.apply(lambda x: stem_fun(x, method='lemma'))  # Apply lemmatization\n",
    "\n",
    "data['cleaned_body']=df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ddfb17-51a1-4a8e-8471-d00bb2a3a10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We use essential cookies to make Venngage wor...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>use essential cooky make Venngage work clickin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A legal contract is a written document that is...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>legal contract written document drawn party ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>November 27 2023 14 min Author Olga Asheychik...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>November 27 2023 14 min Author Olga Asheychik ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerate contracts with AI native workflows ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>Accelerate contract AI native workflow Advance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create smarter agreements commit to them more ...</td>\n",
       "      <td>legal_contract_examples</td>\n",
       "      <td>Create smarter agreement commit efficiently ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body                    label  \\\n",
       "0   We use essential cookies to make Venngage wor...  legal_contract_examples   \n",
       "1  A legal contract is a written document that is...  legal_contract_examples   \n",
       "2   November 27 2023 14 min Author Olga Asheychik...  legal_contract_examples   \n",
       "3  Accelerate contracts with AI native workflows ...  legal_contract_examples   \n",
       "4  Create smarter agreements commit to them more ...  legal_contract_examples   \n",
       "\n",
       "                                        cleaned_body  \n",
       "0  use essential cooky make Venngage work clickin...  \n",
       "1  legal contract written document drawn party ag...  \n",
       "2  November 27 2023 14 min Author Olga Asheychik ...  \n",
       "3  Accelerate contract AI native workflow Advance...  \n",
       "4  Create smarter agreement commit efficiently ma...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3c31374-3c30-45bc-adb7-800f7b6d99ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['legal_contract_examples', 'marketing_material_examples',\n",
       "       'engineering_specification_examples'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "670bd5b0-fe00-41c8-8057-f84d867a538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We use essential cookies to make Venngage wor...</td>\n",
       "      <td>1</td>\n",
       "      <td>use essential cooky make Venngage work clickin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A legal contract is a written document that is...</td>\n",
       "      <td>1</td>\n",
       "      <td>legal contract written document drawn party ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>November 27 2023 14 min Author Olga Asheychik...</td>\n",
       "      <td>1</td>\n",
       "      <td>November 27 2023 14 min Author Olga Asheychik ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerate contracts with AI native workflows ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Accelerate contract AI native workflow Advance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create smarter agreements commit to them more ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Create smarter agreement commit efficiently ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label  \\\n",
       "0   We use essential cookies to make Venngage wor...      1   \n",
       "1  A legal contract is a written document that is...      1   \n",
       "2   November 27 2023 14 min Author Olga Asheychik...      1   \n",
       "3  Accelerate contracts with AI native workflows ...      1   \n",
       "4  Create smarter agreements commit to them more ...      1   \n",
       "\n",
       "                                        cleaned_body  \n",
       "0  use essential cooky make Venngage work clickin...  \n",
       "1  legal contract written document drawn party ag...  \n",
       "2  November 27 2023 14 min Author Olga Asheychik ...  \n",
       "3  Accelerate contract AI native workflow Advance...  \n",
       "4  Create smarter agreement commit efficiently ma...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling cat var \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])  # Converts labels to 0, 1, 2\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c66c5-feea-4f0c-a013-a28b0267150f",
   "metadata": {},
   "source": [
    "# ML functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04e6184e-c717-411c-8bab-b05a962bf110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = data[\"cleaned_body\"]\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom placeholder transformers for embedding types\n",
    "class PretrainedEmbeddingTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return np.random.rand(len(X), 300)  # Replace with real embedding logic\n",
    "\n",
    "class DomainEmbeddingTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return np.random.rand(len(X), 300)  # Replace with real domain-trained embedding logic\n",
    "\n",
    "# Helper function\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, vectorizer, apply_chi2=False, k=1000):\n",
    "    if isinstance(vectorizer, (CountVectorizer, TfidfVectorizer)):\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "        if apply_chi2:\n",
    "            chi2_selector = SelectKBest(chi2, k=min(k, X_train_vec.shape[1]))\n",
    "            X_train_vec = chi2_selector.fit_transform(X_train_vec, y_train)\n",
    "            X_test_vec = chi2_selector.transform(X_test_vec)\n",
    "    else:\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    return precision, recall, fscore\n",
    "\n",
    "# Run all models\n",
    "results = []\n",
    "\n",
    "ngram_ranges = [(1,1), (1,2), (1,3)]\n",
    "vectorizer_types = [\"tf\", \"tfidf\"]\n",
    "chi2_options = [False, True]\n",
    "\n",
    "for ngram in ngram_ranges:\n",
    "    for vec_type in vectorizer_types:\n",
    "        for use_chi2 in chi2_options:\n",
    "            if vec_type == \"tf\":\n",
    "                vectorizer = CountVectorizer(ngram_range=ngram)\n",
    "                vec_name = \"tf\"\n",
    "            else:\n",
    "                vectorizer = TfidfVectorizer(ngram_range=ngram)\n",
    "                vec_name = \"tf-idf\"\n",
    "            \n",
    "            vec_label = f\"{vec_name} {'with' if use_chi2 else 'without'} chi-squared\"\n",
    "            precision, recall, fscore = evaluate_model(X_train, X_test, y_train, y_test, vectorizer, use_chi2)\n",
    "            results.append([\"Random Forest\", ngram, \"body\", vec_label, precision, recall, fscore])\n",
    "\n",
    "# Pretrained embedding\n",
    "for emb_type, transformer in [(\"pre-trained embedding\", PretrainedEmbeddingTransformer()), \n",
    "                              (\"domain embedding\", DomainEmbeddingTransformer())]:\n",
    "    precision, recall, fscore = evaluate_model(X_train, X_test, y_train, y_test, transformer)\n",
    "    results.append([\"Random Forest\", \"N/A\", \"body\", emb_type, precision, recall, fscore])\n",
    "\n",
    "# Final dataframe\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"n-gram\", \"column\", \"vectorizer\", \"precision\", \"recall\", \"fscore\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "020ee565-16b1-47b1-bad5-129046ddcb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  n-gram column                  vectorizer  precision  \\\n",
      "13  Random Forest     N/A   body            domain embedding   0.413603   \n",
      "12  Random Forest     N/A   body       pre-trained embedding   0.382222   \n",
      "1   Random Forest  (1, 1)   body         tf with chi-squared   0.758304   \n",
      "5   Random Forest  (1, 2)   body         tf with chi-squared   0.794771   \n",
      "9   Random Forest  (1, 3)   body         tf with chi-squared   0.744180   \n",
      "0   Random Forest  (1, 1)   body      tf without chi-squared   0.864646   \n",
      "4   Random Forest  (1, 2)   body      tf without chi-squared   0.864646   \n",
      "8   Random Forest  (1, 3)   body      tf without chi-squared   0.864646   \n",
      "3   Random Forest  (1, 1)   body     tf-idf with chi-squared   0.876190   \n",
      "7   Random Forest  (1, 2)   body     tf-idf with chi-squared   0.876190   \n",
      "11  Random Forest  (1, 3)   body     tf-idf with chi-squared   0.876190   \n",
      "2   Random Forest  (1, 1)   body  tf-idf without chi-squared   0.862626   \n",
      "6   Random Forest  (1, 2)   body  tf-idf without chi-squared   0.852086   \n",
      "10  Random Forest  (1, 3)   body  tf-idf without chi-squared   0.840000   \n",
      "\n",
      "      recall    fscore  \n",
      "13  0.422222  0.410643  \n",
      "12  0.377778  0.376908  \n",
      "1   0.733333  0.733912  \n",
      "5   0.755556  0.759387  \n",
      "9   0.733333  0.731388  \n",
      "0   0.822222  0.821972  \n",
      "4   0.822222  0.821972  \n",
      "8   0.822222  0.821972  \n",
      "3   0.844444  0.845376  \n",
      "7   0.844444  0.845376  \n",
      "11  0.844444  0.845376  \n",
      "2   0.822222  0.825229  \n",
      "6   0.800000  0.802214  \n",
      "10  0.777778  0.781674  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = results_df.sort_values(by=['vectorizer', 'n-gram'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7bea457-a839-46cf-ac79-91fe7df2bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('/Users/haleychen/Columbia_NLP/sorted_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
